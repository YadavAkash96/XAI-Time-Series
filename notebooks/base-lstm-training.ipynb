{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b589592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense\n",
    "\n",
    "def build_mic_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=16, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=4),\n",
    "        LSTM(64),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bb418f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_acc = build_lstm_model((41, 3), num_classes=8)\n",
    "model_gyr = build_lstm_model((41, 3), num_classes=8)\n",
    "model_mag = build_lstm_model((62, 3), num_classes=8)\n",
    "\n",
    "# #  This works, but slow and heavy, especially with large sequences.\n",
    "# model_mic = build_lstm_model((3200, 1), num_classes=8)\n",
    "\n",
    "model_mic = build_mic_model((3200, 1), num_classes=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7f980e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_acc = np.array(Xt_acc_clean)     # shape: (7259, 41, 3)\n",
    "# y_acc = to_categorical(y_acc_mapped)\n",
    "\n",
    "# X_gyr = np.array(Xt_gyr_clean)     # shape: (7259, 41, 3)\n",
    "# y_gyr = to_categorical(y_gyr_mapped)\n",
    "\n",
    "# X_mag = np.array(Xt_mag_clean)     # shape: (7219, 62, 3)\n",
    "# y_mag = to_categorical(y_mag_mapped)\n",
    "\n",
    "# X_mic = np.array(Xt_mic_clean)      # shape: (7185, 3200, 1)\n",
    "# y_mic = to_categorical(y_mic_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c609da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('./cleaned_data/electric_screwdriver_dataset_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "036104c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_acc</th>\n",
       "      <th>X_gyr</th>\n",
       "      <th>X_mag</th>\n",
       "      <th>X_mic</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-5.877378, 1.322051, 8.612491], [-5.81989653...</td>\n",
       "      <td>[[-0.01065264, 0.01171791, -0.02130529], [-0.0...</td>\n",
       "      <td>[[0.0002260082, 5.341905e-05, -0.000693571], [...</td>\n",
       "      <td>[[7.0], [-1.0], [-9.0], [-6.0], [-9.0], [-11.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.7765572746195495, -3.3777170393376266, 10....</td>\n",
       "      <td>[[0.2405253416105745, -0.1589432131596917, 0.5...</td>\n",
       "      <td>[[-0.00017548574, 0.0002208949812538, 0.000350...</td>\n",
       "      <td>[[-176.0], [-222.0], [-295.0], [-398.0], [-479...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-4.661880464586655, 1.9574543543611933, 8.63...</td>\n",
       "      <td>[[-0.4239807449647005, -0.1303672858574356, 0....</td>\n",
       "      <td>[[0.0002206308612263, 5.172351082169609e-05, -...</td>\n",
       "      <td>[[20.0], [19.0], [16.0], [9.0], [9.0], [12.0],...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.2243101964783376, 0.8909580531877421, 6.9...</td>\n",
       "      <td>[[0.7246870594223318, 0.0347562930971468, 0.17...</td>\n",
       "      <td>[[-0.0001836712355924, 0.000201727285763, 0.00...</td>\n",
       "      <td>[[264.0], [325.0], [218.0], [4.0], [-334.0], [...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-4.654718747731929, 1.6489709338113354, 8.58...</td>\n",
       "      <td>[[-0.7671679936250123, -0.3679601965661887, 0....</td>\n",
       "      <td>[[0.0002186657774452, 5.5124810577497975e-05, ...</td>\n",
       "      <td>[[15.0], [7.0], [-7.0], [-14.0], [-18.0], [-11...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>[[-0.4435225921488645, 1.446229573999129, 9.67...</td>\n",
       "      <td>[[1.5150272513234182, 0.2443794430437472, 0.08...</td>\n",
       "      <td>[[-0.0001829688242856, 0.0002077097255544, 0.0...</td>\n",
       "      <td>[[32.0], [33.0], [30.0], [30.0], [26.0], [17.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>[[-0.3560756462892959, -3.229175592151793, 9.6...</td>\n",
       "      <td>[[-1.704929743579738, -0.2662585630831891, 0.1...</td>\n",
       "      <td>[[-0.0001818928115718, 0.0002072522331499, 0.0...</td>\n",
       "      <td>[[-12.0], [-8.0], [-6.0], [-7.0], [-10.0], [-1...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>[[-0.5858299366003309, -5.146209871058921, 9.0...</td>\n",
       "      <td>[[-1.1219787501838403, 0.1069062964748598, 0.0...</td>\n",
       "      <td>[[-0.0001823644517704, 0.0002003066688551, 0.0...</td>\n",
       "      <td>[[8.0], [25.0], [31.0], [-1.0], [-72.0], [-103...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>[[-0.144674183359998, -2.698030852888813, 9.14...</td>\n",
       "      <td>[[3.119370343340732, 0.0056913177676755, 0.446...</td>\n",
       "      <td>[[-0.0001829336829628, 0.0002016430804244, 0.0...</td>\n",
       "      <td>[[-91.0], [-93.0], [-88.0], [-54.0], [0.0], [4...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>[[-0.6124043738554599, 4.364567202346398, 9.08...</td>\n",
       "      <td>[[-0.7115167660601478, -0.0042009596290397, -0...</td>\n",
       "      <td>[[-0.0001793801893456, 0.0002081338750783, 0.0...</td>\n",
       "      <td>[[-2.0], [-3.0], [-4.0], [-11.0], [-17.0], [-2...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7177 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  X_acc  \\\n",
       "0     [[-5.877378, 1.322051, 8.612491], [-5.81989653...   \n",
       "1     [[0.7765572746195495, -3.3777170393376266, 10....   \n",
       "2     [[-4.661880464586655, 1.9574543543611933, 8.63...   \n",
       "3     [[-0.2243101964783376, 0.8909580531877421, 6.9...   \n",
       "4     [[-4.654718747731929, 1.6489709338113354, 8.58...   \n",
       "...                                                 ...   \n",
       "7172  [[-0.4435225921488645, 1.446229573999129, 9.67...   \n",
       "7173  [[-0.3560756462892959, -3.229175592151793, 9.6...   \n",
       "7174  [[-0.5858299366003309, -5.146209871058921, 9.0...   \n",
       "7175  [[-0.144674183359998, -2.698030852888813, 9.14...   \n",
       "7176  [[-0.6124043738554599, 4.364567202346398, 9.08...   \n",
       "\n",
       "                                                  X_gyr  \\\n",
       "0     [[-0.01065264, 0.01171791, -0.02130529], [-0.0...   \n",
       "1     [[0.2405253416105745, -0.1589432131596917, 0.5...   \n",
       "2     [[-0.4239807449647005, -0.1303672858574356, 0....   \n",
       "3     [[0.7246870594223318, 0.0347562930971468, 0.17...   \n",
       "4     [[-0.7671679936250123, -0.3679601965661887, 0....   \n",
       "...                                                 ...   \n",
       "7172  [[1.5150272513234182, 0.2443794430437472, 0.08...   \n",
       "7173  [[-1.704929743579738, -0.2662585630831891, 0.1...   \n",
       "7174  [[-1.1219787501838403, 0.1069062964748598, 0.0...   \n",
       "7175  [[3.119370343340732, 0.0056913177676755, 0.446...   \n",
       "7176  [[-0.7115167660601478, -0.0042009596290397, -0...   \n",
       "\n",
       "                                                  X_mag  \\\n",
       "0     [[0.0002260082, 5.341905e-05, -0.000693571], [...   \n",
       "1     [[-0.00017548574, 0.0002208949812538, 0.000350...   \n",
       "2     [[0.0002206308612263, 5.172351082169609e-05, -...   \n",
       "3     [[-0.0001836712355924, 0.000201727285763, 0.00...   \n",
       "4     [[0.0002186657774452, 5.5124810577497975e-05, ...   \n",
       "...                                                 ...   \n",
       "7172  [[-0.0001829688242856, 0.0002077097255544, 0.0...   \n",
       "7173  [[-0.0001818928115718, 0.0002072522331499, 0.0...   \n",
       "7174  [[-0.0001823644517704, 0.0002003066688551, 0.0...   \n",
       "7175  [[-0.0001829336829628, 0.0002016430804244, 0.0...   \n",
       "7176  [[-0.0001793801893456, 0.0002081338750783, 0.0...   \n",
       "\n",
       "                                                  X_mic  \\\n",
       "0     [[7.0], [-1.0], [-9.0], [-6.0], [-9.0], [-11.0...   \n",
       "1     [[-176.0], [-222.0], [-295.0], [-398.0], [-479...   \n",
       "2     [[20.0], [19.0], [16.0], [9.0], [9.0], [12.0],...   \n",
       "3     [[264.0], [325.0], [218.0], [4.0], [-334.0], [...   \n",
       "4     [[15.0], [7.0], [-7.0], [-14.0], [-18.0], [-11...   \n",
       "...                                                 ...   \n",
       "7172  [[32.0], [33.0], [30.0], [30.0], [26.0], [17.0...   \n",
       "7173  [[-12.0], [-8.0], [-6.0], [-7.0], [-10.0], [-1...   \n",
       "7174  [[8.0], [25.0], [31.0], [-1.0], [-72.0], [-103...   \n",
       "7175  [[-91.0], [-93.0], [-88.0], [-54.0], [0.0], [4...   \n",
       "7176  [[-2.0], [-3.0], [-4.0], [-11.0], [-17.0], [-2...   \n",
       "\n",
       "                                             y  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "...                                        ...  \n",
       "7172  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "7173  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "7174  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "7175  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "7176  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "\n",
       "[7177 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f38c9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_acc = np.array(df['X_acc'])\n",
    "X_acc = np.stack(X_acc)\n",
    "\n",
    "X_gyr = np.array(df['X_gyr'])\n",
    "X_gyr = np.stack(X_gyr)\n",
    "\n",
    "X_mag = np.array(df['X_mag'])\n",
    "X_mag = np.stack(X_mag)\n",
    "\n",
    "X_mic = np.array(df['X_mic'])\n",
    "X_mic = np.stack(X_mic)\n",
    "\n",
    "y = np.array(df['y'])\n",
    "y = np.stack(y)\n",
    "\n",
    "print(type(X_acc), type(X_gyr),type(X_mag),type(X_mic), type(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93780323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert one-hot vectors to class labels\n",
    "# Assumes only one '1' per vector\n",
    "y_class = np.array([np.argmax(label) for label in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cd1c72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7177, 41, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59c62040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/test split per sensor\n",
    "X_acc_train, X_acc_test, y_acc_train, y_acc_test = train_test_split(X_acc, y, test_size=0.2, stratify=y_class, random_state=42)\n",
    "X_gyr_train, X_gyr_test, y_gyr_train, y_gyr_test = train_test_split(X_gyr, y, test_size=0.2, stratify=y_class, random_state=42)\n",
    "X_mag_train, X_mag_test, y_mag_train, y_mag_test = train_test_split(X_mag, y, test_size=0.2, stratify=y_class, random_state=42)\n",
    "X_mic_train, X_mic_test, y_mic_train, y_mic_test = train_test_split(X_mic, y, test_size=0.2, stratify=y_class, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39d64db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_class))\n",
    "model_acc = build_lstm_model((41, 3), num_classes)\n",
    "model_gyr = build_lstm_model((41, 3), num_classes)\n",
    "model_mag = build_lstm_model((62, 3), num_classes)\n",
    "model_mic = build_mic_model((3200, 1), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4063e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6074 - loss: 1.3653 - val_accuracy: 0.7570 - val_loss: 0.8721\n",
      "Epoch 2/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7588 - loss: 0.7934 - val_accuracy: 0.8294 - val_loss: 0.5294\n",
      "Epoch 3/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8333 - loss: 0.4731 - val_accuracy: 0.8524 - val_loss: 0.5020\n",
      "Epoch 4/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8567 - loss: 0.4414 - val_accuracy: 0.8921 - val_loss: 0.3537\n",
      "Epoch 5/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8751 - loss: 0.3616 - val_accuracy: 0.8962 - val_loss: 0.3340\n",
      "Epoch 6/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8787 - loss: 0.3527 - val_accuracy: 0.9011 - val_loss: 0.3201\n",
      "Epoch 7/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8895 - loss: 0.3085 - val_accuracy: 0.9053 - val_loss: 0.2924\n",
      "Epoch 8/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8917 - loss: 0.2874 - val_accuracy: 0.9150 - val_loss: 0.2709\n",
      "Epoch 9/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9006 - loss: 0.2585 - val_accuracy: 0.9206 - val_loss: 0.2614\n",
      "Epoch 10/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9229 - loss: 0.2274 - val_accuracy: 0.9143 - val_loss: 0.2714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27407b9b910>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_acc.fit(X_acc_train, y_acc_train, validation_data=(X_acc_test, y_acc_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf768237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6940 - loss: 1.3592 - val_accuracy: 0.7584 - val_loss: 0.8642\n",
      "Epoch 2/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7560 - loss: 0.8943 - val_accuracy: 0.7604 - val_loss: 0.8741\n",
      "Epoch 3/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7624 - loss: 0.8689 - val_accuracy: 0.7639 - val_loss: 0.8371\n",
      "Epoch 4/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7722 - loss: 0.8141 - val_accuracy: 0.7639 - val_loss: 0.8067\n",
      "Epoch 5/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7709 - loss: 0.7847 - val_accuracy: 0.7695 - val_loss: 0.8001\n",
      "Epoch 6/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7706 - loss: 0.7523 - val_accuracy: 0.7674 - val_loss: 0.7312\n",
      "Epoch 7/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7749 - loss: 0.7175 - val_accuracy: 0.7792 - val_loss: 0.6916\n",
      "Epoch 8/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7741 - loss: 0.6895 - val_accuracy: 0.7242 - val_loss: 0.7151\n",
      "Epoch 9/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7777 - loss: 0.6762 - val_accuracy: 0.7639 - val_loss: 0.6623\n",
      "Epoch 10/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7876 - loss: 0.6207 - val_accuracy: 0.7883 - val_loss: 0.6494\n",
      "Epoch 1/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7262 - loss: 1.3403 - val_accuracy: 0.7556 - val_loss: 0.9196\n",
      "Epoch 2/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7593 - loss: 0.9089 - val_accuracy: 0.7556 - val_loss: 0.9205\n",
      "Epoch 3/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7624 - loss: 0.9059 - val_accuracy: 0.7556 - val_loss: 0.9214\n",
      "Epoch 4/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7598 - loss: 0.9166 - val_accuracy: 0.7556 - val_loss: 0.9203\n",
      "Epoch 5/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7628 - loss: 0.9053 - val_accuracy: 0.7556 - val_loss: 0.9199\n",
      "Epoch 6/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7564 - loss: 0.9236 - val_accuracy: 0.7556 - val_loss: 0.9192\n",
      "Epoch 7/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7640 - loss: 0.8994 - val_accuracy: 0.7556 - val_loss: 0.9231\n",
      "Epoch 8/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7668 - loss: 0.8914 - val_accuracy: 0.7556 - val_loss: 0.9219\n",
      "Epoch 9/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7534 - loss: 0.9321 - val_accuracy: 0.7556 - val_loss: 0.9212\n",
      "Epoch 10/10\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7471 - loss: 0.9491 - val_accuracy: 0.7556 - val_loss: 0.9233\n",
      "Epoch 1/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 175ms/step - accuracy: 0.6915 - loss: 1.0752 - val_accuracy: 0.8210 - val_loss: 0.5412\n",
      "Epoch 2/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 172ms/step - accuracy: 0.8277 - loss: 0.5516 - val_accuracy: 0.8628 - val_loss: 0.4693\n",
      "Epoch 3/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 173ms/step - accuracy: 0.8738 - loss: 0.4408 - val_accuracy: 0.8712 - val_loss: 0.4141\n",
      "Epoch 4/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 173ms/step - accuracy: 0.8746 - loss: 0.4120 - val_accuracy: 0.8788 - val_loss: 0.4066\n",
      "Epoch 5/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 174ms/step - accuracy: 0.8923 - loss: 0.3641 - val_accuracy: 0.8802 - val_loss: 0.4069\n",
      "Epoch 6/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 181ms/step - accuracy: 0.8846 - loss: 0.3767 - val_accuracy: 0.8858 - val_loss: 0.3887\n",
      "Epoch 7/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 199ms/step - accuracy: 0.8737 - loss: 0.4048 - val_accuracy: 0.8893 - val_loss: 0.3834\n",
      "Epoch 8/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 197ms/step - accuracy: 0.8869 - loss: 0.3548 - val_accuracy: 0.8795 - val_loss: 0.3970\n",
      "Epoch 9/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 195ms/step - accuracy: 0.8854 - loss: 0.3681 - val_accuracy: 0.8907 - val_loss: 0.3696\n",
      "Epoch 10/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 195ms/step - accuracy: 0.8867 - loss: 0.3709 - val_accuracy: 0.8879 - val_loss: 0.3704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27436397fd0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gyr.fit(X_gyr_train, y_gyr_train, validation_data=(X_gyr_test, y_gyr_test), epochs=10, batch_size=32)\n",
    "model_mag.fit(X_mag_train, y_mag_train, validation_data=(X_mag_test, y_mag_test), epochs=10, batch_size=32)\n",
    "model_mic.fit(X_mic_train, y_mic_train, validation_data=(X_mic_test, y_mic_test), epochs=10, batch_size=16)  # MIC: large input → smaller batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e84b1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc.save('./trained_models/model_acc.keras')  \n",
    "model_gyr.save('./trained_models/model_gyr.keras')\n",
    "model_mag.save('./trained_models/model_mag.keras')\n",
    "model_mic.save('./trained_models/model_mic.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e814f3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# --- Post-training: Prediction fusion for 4 sensor models (ACC, GYR, MAG, MIC) ---\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Predict probabilities from each trained model ---\n",
    "p_acc = model_acc.predict(X_acc_test)\n",
    "p_gyr = model_gyr.predict(X_gyr_test)\n",
    "p_mag = model_mag.predict(X_mag_test)\n",
    "p_mic = model_mic.predict(X_mic_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99063924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436 1436 1436 1436\n"
     ]
    }
   ],
   "source": [
    "y_pred_acc = [np.argmax(p_acc[i]) for i in range(len(p_acc))]\n",
    "y_pred_gyr = [np.argmax(p_gyr[i]) for i in range(len(p_gyr))]\n",
    "y_pred_mag = [np.argmax(p_mag[i]) for i in range(len(p_mag))]\n",
    "y_pred_mic = [np.argmax(p_mic[i]) for i in range(len(p_mic))]\n",
    "\n",
    "print(len(y_pred_acc), len(y_pred_gyr), len(y_pred_mag), len(y_pred_mic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d8c5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_actual = np.array([np.argmax(label) for label in y_acc_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a71f6286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Classification report from fused prediction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       164\n",
      "           1       1.00      0.13      0.24        67\n",
      "           2       1.00      0.02      0.03        60\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.90      0.53      0.67        17\n",
      "           6       0.88      1.00      0.93      1085\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87      1436\n",
      "   macro avg       0.58      0.32      0.34      1436\n",
      "weighted avg       0.86      0.87      0.82      1436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# --- Fuse using soft voting (average the probability distributions) ---\n",
    "p_fused = (p_acc + p_gyr + p_mag + p_mic) / 4.0\n",
    "y_pred_fused = np.argmax(p_fused, axis=1)\n",
    "\n",
    "# y_class = np.array([np.argmax(label) for label in y])\n",
    "# # # --- Use one aligned test label set for ground truth ---\n",
    "# # y_true = np.argmax(y_class, axis=1)\n",
    "\n",
    "\n",
    "# y_class_test = np.array([np.argmax(label) for label in y])\n",
    "# # print(y_class.shape,y_pred_fused.shape)\n",
    "\n",
    "# --- Evaluation ---\n",
    "print(\"[INFO] Classification report from fused prediction:\")\n",
    "print(classification_report(y_test_actual, y_pred_fused))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4cb29398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# import numpy as np\n",
    "\n",
    "# # Ensure inputs are NumPy arrays\n",
    "# Xt_acc_test = np.array(X_acc_test)\n",
    "\n",
    "# # Sample a background for KernelExplainer\n",
    "# X_background = Xt_acc_test[np.random.choice(len(Xt_acc_test), size=100, replace=False)]\n",
    "\n",
    "# # Use kernel-based model-agnostic SHAP\n",
    "# explainer = shap.KernelExplainer(model_acc.predict, X_background)\n",
    "\n",
    "# # Explain first 5 examples\n",
    "# shap_values = explainer.shap_values(Xt_acc_test[:5])\n",
    "\n",
    "# # Visualize\n",
    "# shap.summary_plot(shap_values, Xt_acc_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e1a55f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D to 2D wrapper\n",
    "def f_model_flattened(X_flat):\n",
    "    X = X_flat.reshape((-1, 41, 3))\n",
    "    return model_acc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0fa89b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n"
     ]
    }
   ],
   "source": [
    "X_background = X_acc_test[np.random.choice(len(X_acc_test), size=1, replace=False)]\n",
    "X_background_flat = X_background.reshape((X_background.shape[0], -1))  # shape: (100, 123)\n",
    "\n",
    "explainer = shap.KernelExplainer(f_model_flattened, X_background_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4e921a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8899aa2539e4401a93796afc0c227e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_background = X_acc_test[np.random.choice(len(X_acc_test), size=1, replace=False)]\n",
    "X_background_flat = X_background.reshape((X_background.shape[0], -1))  # shape: (100, 123)\n",
    "\n",
    "shap_values = explainer.shap_values(X_background_flat)\n",
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "eb25af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gshub\\AppData\\Local\\Temp\\ipykernel_28924\\2699567980.py:1: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_background_flat[:500])\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:726: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:746: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:746: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:746: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:746: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:746: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n",
      "c:\\Uni Stuff\\Semester 4\\ADLTS\\exAI-timeseries-tool-tracking-data\\.env\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:746: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, X_background_flat[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
